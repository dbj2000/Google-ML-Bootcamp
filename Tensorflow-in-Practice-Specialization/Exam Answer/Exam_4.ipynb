{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exam_4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNc9s3DRnjthLPprj7IBq7W"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6e9szZa1HHI","executionInfo":{"status":"ok","timestamp":1611669837118,"user_tz":-540,"elapsed":7566,"user":{"displayName":"진현영","photoUrl":"https://lh5.googleusercontent.com/-JblkEZU_9CA/AAAAAAAAAAI/AAAAAAAAA9E/pPczc2xYDZs/s64/photo.jpg","userId":"17511610036703028721"}},"outputId":"cb059b90-1255-4c26-d5f4-dc5b6d65448c"},"source":["import json\r\n","import tensorflow as tf\r\n","import numpy as np\r\n","import urllib\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","\r\n","\r\n","def solution_model():\r\n","\r\n","    class myCallback(tf.keras.callbacks.Callback):\r\n","      def on_epoch_end(self, epoch, logs={}):\r\n","          if(logs.get('accuracy') > 0.9):\r\n","              print(\"Reached 99% accuracy so cancelling trining!\")\r\n","              self.model.stop_training = True\r\n","\r\n","    callbacks = myCallback()\r\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\r\n","    urllib.request.urlretrieve(url, 'sarcasm.json')\r\n","\r\n","    # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\r\n","    vocab_size = 1000\r\n","    embedding_dim = 16\r\n","    max_length = 120\r\n","    trunc_type='post'\r\n","    padding_type='post'\r\n","    oov_tok = \"<OOV>\"\r\n","    training_size = 20000\r\n","\r\n","    sentences = []\r\n","    labels = []\r\n","    # YOUR CODE HERE\r\n","\r\n","    with open('sarcasm.json', 'r') as f:\r\n","      data = json.load(f)\r\n","\r\n","    for d in data:\r\n","      sentences.append(d['headline'])\r\n","      labels.append(d['is_sarcastic'])\r\n","\r\n","    train_ratio = 0.8\r\n","    train_size = int(len(data) * train_ratio)\r\n","\r\n","    # train 분할\r\n","    train_sentences = sentences[:train_size]\r\n","    valid_sentences = sentences[train_size:]\r\n","    # label 분할\r\n","    train_labels = labels[:train_size]\r\n","    valid_labels = labels[train_size:]\r\n","\r\n","    token = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\r\n","    token.fit_on_texts(sentences)\r\n","    word_index = token.word_index\r\n","\r\n","    train_sequences = token.texts_to_sequences(train_sentences)\r\n","    valid_sequences = token.texts_to_sequences(valid_sentences)\r\n","\r\n","    train_padded = pad_sequences(train_sequences, truncating=trunc_type, padding=padding_type, maxlen=max_length)\r\n","    valid_padded = pad_sequences(valid_sequences, truncating=trunc_type, padding=padding_type, maxlen=max_length)\r\n","\r\n","    train_labels = np.asarray(train_labels)\r\n","    valid_labels = np.asarray(valid_labels)\r\n","\r\n","    model = tf.keras.Sequential([\r\n","    # YOUR CODE HERE. KEEP THIS OUTPUT LAYER INTACT OR TESTS MAY FAIL\r\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\r\n","        # tf.keras.layers.Flatten(),\r\n","        tf.keras.layers.GlobalAveragePooling1D(),\r\n","        tf.keras.layers.Dense(16, activation='relu'),\r\n","        tf.keras.layers.Dense(1, activation='sigmoid')\r\n","    ])\r\n","\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n","\r\n","    model.fit(train_padded, train_labels, \r\n","                    validation_data=(valid_padded, valid_labels),\r\n","                    epochs=5, \r\n","                    verbose=2,\r\n","                    callbacks=[callbacks])\r\n","    return model\r\n","\r\n","\r\n","# Note that you'll need to save your model as a .h5 like this.\r\n","# When you press the Submit and Test button, your saved .h5 model will\r\n","# be sent to the testing infrastructure for scoring\r\n","# and the score will be returned to you.\r\n","if __name__ == '__main__':\r\n","    model = solution_model()\r\n","    model.save(\"mymodel.h5\")\r\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","668/668 - 2s - loss: 0.6657 - accuracy: 0.5840 - val_loss: 0.6014 - val_accuracy: 0.7606\n","Epoch 2/5\n","668/668 - 1s - loss: 0.4934 - accuracy: 0.7821 - val_loss: 0.4451 - val_accuracy: 0.7988\n","Epoch 3/5\n","668/668 - 1s - loss: 0.4089 - accuracy: 0.8183 - val_loss: 0.4192 - val_accuracy: 0.8055\n","Epoch 4/5\n","668/668 - 1s - loss: 0.3873 - accuracy: 0.8234 - val_loss: 0.4119 - val_accuracy: 0.8091\n","Epoch 5/5\n","668/668 - 1s - loss: 0.3736 - accuracy: 0.8307 - val_loss: 0.3981 - val_accuracy: 0.8173\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"DuCX5PK91O5X","executionInfo":{"status":"ok","timestamp":1611669847973,"user_tz":-540,"elapsed":875,"user":{"displayName":"진현영","photoUrl":"https://lh5.googleusercontent.com/-JblkEZU_9CA/AAAAAAAAAAI/AAAAAAAAA9E/pPczc2xYDZs/s64/photo.jpg","userId":"17511610036703028721"}},"outputId":"4e06d25b-90e5-471a-c54e-6c60a37cf065"},"source":["from google.colab import files\r\n","files.download(\"mymodel.h5\")"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_ecef4593-3583-40e6-b9d2-6ca2d33da6c1\", \"mymodel.h5\", 225696)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jI1jLekG9uCT"},"source":[""],"execution_count":null,"outputs":[]}]}